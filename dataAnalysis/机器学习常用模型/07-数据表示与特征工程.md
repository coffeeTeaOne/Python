## 数据表示与特征工程



分类特征：

- 描述一件 产品的属性，但是不以连续的方式变化，如一个产品的品牌、颜色



1. 过滤空值，数据有效化
2. 统计特征的values数量，`df.column.value_counts()`

   


### 分类变量

表示分类变量最常用的方法就是**one-hot编码** 或**N取一编码**，也叫虚拟变量

虚拟变量的思想就是将一个分类变量替换为一个或者多个新的特征 



#### one-hot编码

两种方法：

- 使用`pandas`自带的 `get_dummies()` 函数，自动变换所有具有对象类型的列或者所有分类的列，自动将其转化为分类数值
  - `pd.get_dummies(df)`
- 使用sklearn的 OneHotEncoder

数据之间不存在关联性，使用矩阵表示

```python
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# 标签化处理，将文本变为数字
label_enc = LabelEncoder()
X_train_labeled = label_enc.fit_transform(X_train)
# 独热编码，转化为矩阵
oneHot = OneHotEncoder()
X_train_ = oneHot.fit_transform(X_train_labeled)
```



### 特征选择

```python

from sklearn.datasets import load_iris

data = load_iris().data
target = load_iris().target

# 基于方差选择  Filter
from sklearn.feature_selection import VarianceThreshold

# 方差小于 threshold 的会被过滤掉
vt = VarianceThreshold(threshold=0.5)
data_vt = vt.fit_transform(data)
data_vt.std(axis=0)

# 递归特征消除法 Wrapper
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

# 构建算法
logistic = LogisticRegression()
# 指定保留的特征个数，每次递归删除系数最小的特征，知道指定的数目
rfe = RFE(logistic,n_features_to_select=2)
rfe.fit_transform(data)

# 基于惩罚项的选择
from sklearn.feature_selection import SelectFromModel
from sklearn.linear_model import LogisticRegression

# 基于惩罚项的的逻辑斯蒂回归最为基础模型进行选择
# L2 列方向， L1 行方向, penalty 正则化方式
logistic = LogisticRegression(penalty='l1', C=0.1)
SelectFromModel(logistic).fit_transform(data,target)

# 基于数模型的特征选择
# 梯度提升决策树 GBDT 通过不断拟合来优化，接近真实值
from sklearn.ensemble import GradientBoostingClassifier
gbdt = GradientBoostingClassifier()
SelectFromModel(gbdt).fit_transform(data,target)

```

