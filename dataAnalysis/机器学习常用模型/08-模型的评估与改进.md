## 模型的评估与改进

在 `sklearn.model_selection` 中的包，实现这些功能

### 1. sklearn中的交叉验证

`cross_val_score(model_name, data,target,cv=5)`

参数 cv 指定验证策略,默认 cv=5

查看模型的稳定性

#### 分层K折交叉验证

cv=KFold(n_splits=5)

#### 留一法交叉验证

cv=LeaveOneOut()

#### 打乱划分交叉验证

cv=ShuffleSplit(test_size=0.5, train_size=0.5, n_splits=10)

#### 分组交叉验证

cv=GroupKFold(n_split=3)

```python

# 验证不同测试集评分
from sklearn.model_selection import cross_val_score
# 用于分裂样本集
from sklearn.model_selection import KFold

# 将整个样本集分裂成10等份
kf = KFold(n_splits=10)

logistic = LogisticRegression()
score = cross_val_score(logistic, data, target,cv=kf)

```





### 2. 网格搜索

寻找最佳参数

`GridSearchCV(model_name, param_grid, cv=5)`

参数 param_grid 可以是一个字典组成的列表

```python
# 设置参数集合
param_grid = [{
    "kernel":["linear", "rbf"],
    "C":[0.001, 0.01, 0.1, 1, 10, 100],
    "gamma": np.arange(0,10,2)
}]
# 确定算法模型
svc = SVC()
# 创建 grid_cv 对象
grid_cv  = GridSearchCV(svc,param_grid=param_grid)
grid_cv.fit(X_train, y_train)
# 最优参数集
grid_cv.best_params_
# 最优模型
best_svc = grid_cv.best_estimator_
# 预测
best_svc.score(X_train, y_train),best_svc.score(X_test, y_test)
```



#### 准确率召回率曲线





#### 受试者工作特征 （ROC）和 AUC

`from sklearn.metrics import roc_curve`

ROC：受试者工作特征曲线

AUC：ROC曲线下的面积

与准确率-召回率曲线类似，ROC曲线考虑了给定分类器的所有可能的阀值，但它显示的是 假正例率（false positive rate）和真正例率（true positive rate），而不是报告准确率和召回率